{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification_with_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph0AVSX1d5yK"
      },
      "source": [
        "!pip install datasets\n",
        "!pip install tokenizers\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZW1Ztxtd8Xx"
      },
      "source": [
        "from google.colab import drive         \n",
        "drive.mount(\"/content/drive\")     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q4hqy0Jd_0v"
      },
      "source": [
        "from datasets import load_dataset\n",
        "raw_datasets = load_dataset(\"csv\", data_files = {\"train\": \"/content/drive/MyDrive/Colab Notebooks/train_tweets.csv\",\n",
        "                                                  \"test\": \"/content/drive/MyDrive/Colab Notebooks/test_tweets.csv\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLkW47qfeCJD"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkWPMM0WeFIm"
      },
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], max_length = 64, padding = \"max_length\", truncation = True) #max_length'i, veri kümesine göre değiştirebilirsiniz.\n",
        "                                                                                                   #Ben tweetler için 64, haberler için 512 kullandım.\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1SKVVvDeHHV"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "train_dataset = tokenized_datasets[\"train\"].shuffle(seed = 42)               \n",
        "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed = 42)\n",
        "train_dataloader = DataLoader(train_dataset, shuffle = True, batch_size = 32)  #batch_size için 2'nin kuvvetlerini seçmeniz faydalı olucaktır.\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size = 32)                    #Veri kümesine göre farklı değerler kullanmanız gerekebilir."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySeOoxFNUuhp"
      },
      "source": [
        "def average(batch, attention_mask):                                                        \n",
        "    original_length = 0\n",
        "    while original_length < len(attention_mask[0]) and attention_mask[0][original_length]:       \n",
        "        original_length += 1                                                                     \n",
        "\n",
        "    sentence_embeddings = torch.mean(batch[0][1:original_length], 0, True)                       \n",
        "\n",
        "    for i in range(1, len(batch)):                                                               \n",
        "        original_length = 0\n",
        "        while original_length < len(attention_mask[i]) and attention_mask[i][original_length]:\n",
        "            original_length += 1\n",
        "        sentence_embeddings = torch.cat((sentence_embeddings, torch.mean(batch[i][1:original_length], 0, True)), 0)   \n",
        "\n",
        "    return sentence_embeddings  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI8tXX5Leeq-"
      },
      "source": [
        "def hierarchical_avg_max(sentence, mask, window_size):                               \n",
        "    original_length = 0\n",
        "    while original_length < len(mask) and mask[original_length]:                                 \n",
        "        original_length += 1\n",
        "\n",
        "    original_window = original_length-window_size+1                                  \n",
        "                                                                                              \n",
        "    if original_window > 2:                                                               \n",
        "        sentence = torch.reshape(sentence, (sentence.shape[0], 1, sentence.shape[1]))     \n",
        "        window = sentence[0]\n",
        "        for i in range(1, window_size):\n",
        "            window = torch.cat((window, sentence[i]), 0)\n",
        "        windows = torch.mean(window, 0, True)                                             \n",
        "\n",
        "        for i in range(1, sentence.shape[0] - window_size + 1):\n",
        "            window = sentence[i]\n",
        "            for j in range(i + 1, i + window_size):\n",
        "                window = torch.cat((window, sentence[j]), 0)\n",
        "            windows = torch.cat((windows, torch.mean(window, 0, True)), 0)               \n",
        "\n",
        "        sentence_embeddings = torch.reshape(torch.max(windows[1:original_window-1], 0, True)[0], (1, sentence.shape[-1]))  \n",
        "    else:\n",
        "        sentence_embeddings = torch.mean(sentence[1:original_length-1], 0, True)     \n",
        "                                                                                     \n",
        "    return sentence_embeddings                                                       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU7Pjgk9eeuO"
      },
      "source": [
        "def hierarchical_max_avg(sentence, mask, window_size):                           \n",
        "    original_length = 0                                                          \n",
        "    while original_length < len(mask) and mask[original_length]:\n",
        "        original_length += 1\n",
        "\n",
        "    original_window = original_length-window_size+1\n",
        "\n",
        "    if original_window > 2:\n",
        "        sentence = torch.reshape(sentence, (sentence.shape[0], 1, sentence.shape[1]))\n",
        "        window = sentence[0]\n",
        "        for i in range(1, window_size):\n",
        "            window = torch.cat((window, sentence[i]), 0)\n",
        "        windows = torch.max(window, 0, True)[0]\n",
        "\n",
        "        for i in range(1, sentence.shape[0] - window_size + 1):\n",
        "            window = sentence[i]\n",
        "            for j in range(i + 1, i + window_size):\n",
        "                window = torch.cat((window, sentence[j]), 0)\n",
        "            windows = torch.cat((windows, torch.max(window, 0, True)[0]), 0)\n",
        "\n",
        "        sentence_embeddings = torch.reshape(torch.mean(windows[1:original_window-1], 0, True), (1, sentence.shape[-1]))\n",
        "    else:\n",
        "        sentence_embeddings = torch.max(sentence[1:original_length-1], 0, True)[0]\n",
        "\n",
        "    return sentence_embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0aPC1d2ee76"
      },
      "source": [
        "def hierarchical(batch, attention_mask, primary = \"avg\", window_size = 2):               \n",
        "    if prio == \"avg\":                                                                    \n",
        "        hierarchical_prio = hierarchical_avg_max                                          \n",
        "    elif prio == \"max\":                                                                       \n",
        "        hierarchical_prio = hierarchical_max_avg                                              \n",
        "\n",
        "    sentence_embeddings = hierarchical_prio(batch[0], attention_mask[0], window_size)         \n",
        "    for i in range(1, len(batch)):\n",
        "        sentence_embeddings = torch.cat((sentence_embeddings, hierarchical_prio(batch[i], attention_mask[i], window_size)), 0) \n",
        "\n",
        "    return sentence_embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmZKimpleKUE"
      },
      "source": [
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "import torch\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "    def __init__(self, pretrained:str, freeze_bert = False, num_classes = 2, pooling_strategy = \"cls\", pooling_output_layer = -1, hierarchical_window_size = 2):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        D_in, H, D_out = 768, 50, num_classes\n",
        "        self.bert = BertModel.from_pretrained(pretrained)                                      \n",
        "        self.classifier = nn.Sequential(nn.Linear(D_in, H), nn.ReLU(), nn.Linear(H, D_out))   \n",
        "        self.pooling_strategy = pooling_strategy                                               \n",
        "        self.pooling_output_layer = pooling_output_layer                                       \n",
        "        self.hierarchical_window_size = hierarchical_window_size                               \n",
        "\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, output_hidden_states = True):\n",
        "        outputs = self.bert(input_ids = input_ids, attention_mask = attention_mask, output_hidden_states = output_hidden_states)   \n",
        "        \n",
        "        if self.pooling_strategy == \"cls\":                                               \n",
        "            sentence_embeddings = outputs[1]\n",
        "        else:\n",
        "            batch = outputs[2][self.pooling_output_layer]\n",
        "            if self.pooling_strategy == \"average\":\n",
        "                sentence_embeddings = average(batch, attention_mask)\n",
        "            elif self.pooling_strategy == \"hierarchical_avg_max\":\n",
        "                sentence_embeddings = hierarchical(batch, attention_mask, \"avg\", self.hierarchical_window_size)\n",
        "            elif self.pooling_strategy == \"hierarchical_max_avg\":\n",
        "                sentence_embeddings = hierarchical(batch, attention_mask, \"max\", self.hierarchical_window_size)\n",
        "            else:\n",
        "              raise Exception(f\"{self.pooling_strategy} is not recognized as a pooling strategy!\")    \n",
        "\n",
        "        logits = self.classifier(sentence_embeddings.to(device))                        \n",
        "        return logits      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDsRjrKG4tDi"
      },
      "source": [
        "#Modeli farklı seçenekler ile test etmek için yalnızca bu satırdaki parametreleri değiştirmek.\n",
        "#num_classes'a veri kümenizdeki label sayısını atadıktan sonra diğer parametreleri keyfinize göre değiştirebilirsiniz.\n",
        "\n",
        "model = BertClassifier(\"dbmdz/bert-base-turkish-cased\", num_classes = 3, pooling_strategy = \"hierarchical_avg_max\", pooling_output_layer = -1, hierarchical_window_size = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw7LIfmleKcj"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()                   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpY75jRKeR-O"
      },
      "source": [
        "from transformers import AdamW                     \n",
        "optimizer = AdamW(model.parameters(), lr = 5e-5)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjtXJeOReTdG"
      },
      "source": [
        "from transformers import get_scheduler\n",
        "num_epochs = 2                                                      \n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\"linear\", optimizer = optimizer, num_warmup_steps = 0, num_training_steps = num_training_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUSZ6OxGeWay"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")   \n",
        "model.to(device)                                                                     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_i36ZqDebJ0"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "    print(\"-\"*70)\n",
        "    t0_epoch, t0_batch = time.time(), time.time()\n",
        "    model.train()\n",
        "    total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch_counts +=1\n",
        "        b_input_ids = batch[\"input_ids\"].to(device)\n",
        "        b_attn_mask = batch[\"attention_mask\"].to(device)\n",
        "        b_labels = batch[\"labels\"].type(torch.LongTensor).to(device)\n",
        "        model.zero_grad()     \n",
        "        logits = model(b_input_ids, b_attn_mask)\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        batch_loss += loss.item()\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "        if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "            time_elapsed = time.time() - t0_batch\n",
        "            print(f\"{epoch + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "            batch_loss, batch_counts = 0, 0\n",
        "            t0_batch = time.time()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    val_loss = []\n",
        "    val_accuracy = []\n",
        "    model.eval()\n",
        "    for batch in eval_dataloader:\n",
        "        b_input_ids = batch[\"input_ids\"].to(device)\n",
        "        b_attn_mask = batch[\"attention_mask\"].to(device)\n",
        "        b_labels = batch[\"labels\"].type(torch.LongTensor).to(device)\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "        \n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "    time_elapsed = time.time() - t0_epoch\n",
        "    print(f\"{epoch + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "    print(\"-\"*70)\n",
        "    print(\"\\n\")\n",
        "\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}